from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from pathlib import Path


# vector_db ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì • (2ë‹¨ê³„ì—ì„œ ìƒì„±í•œ DB ì‚¬ìš©)
VECTOR_DB_DIR = Path(__file__).resolve().parent.parent.parent /"02_document_embedding"/ "vector_db"

def retrieve_relevant_documents(query: str, top_k: int = 3):
    try:
        print(f"ğŸ” ë²¡í„° DB ê²½ë¡œ: {VECTOR_DB_DIR}")
        embedder = HuggingFaceEmbeddings(model_name="snunlp/KR-SBERT-V40K-klueNLI-augSTS")
        print(f"ğŸ” ë²¡í„° DB ë¡œë”© ì¤‘...")
        
        # FAISS ë²¡í„° DB ë¡œë“œ
        vectordb = FAISS.load_local(str(VECTOR_DB_DIR)
                                        , embedder
                                        , allow_dangerous_deserialization=True) # í•´ë‹¹ ì˜µì…˜ì€ ë³´ì•ˆ ì´ìŠˆê°€ ìˆê¸° ë•Œë¬¸ì— ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¢‹ìŒ
        print(f"ğŸ” ë²¡í„° DB ë¡œë”© ì™„ë£Œ")
        
        if not VECTOR_DB_DIR.exists():
            print("âŒ ë²¡í„° DB ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return []

        print(f"ğŸ” ê²€ìƒ‰ ì¤‘...")
        results = vectordb.similarity_search(query, k=top_k)
        print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}")
        return results
    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []